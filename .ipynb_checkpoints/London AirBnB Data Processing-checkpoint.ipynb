{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Purpose\n",
    "The purpose of this analysis is to perform data processing for COVID AirBnB analysis.\n",
    "\n",
    "## Methodology\n",
    "The data was obtained from AirBnB inside data [and COVID data] TBC. \n",
    "1. Zipped data files are renamed and unzipped\n",
    "2. Data files are processed for subsequent analysis \n",
    "3. Data files are read back as feather format for faster subsequent ingestion.\n",
    "\n",
    "## WIP - improvements\n",
    "\n",
    "## Results\n",
    "\n",
    "## Suggested next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, time, timedelta\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import re \n",
    "\n",
    "# Data manipulation variables\n",
    "also = ' and '\n",
    "\n",
    "# Classification accuracy \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 30\n",
    "\n",
    "# Visualizations\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as ply\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "import cufflinks as cf\n",
    "cf.go_offline(connected=True)\n",
    "cf.set_config_file(theme='white')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Visualisation options\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Date parsers\n",
    "dparser = lambda date: pd.datetime.strptime(date, '%d/%m/%Y %H:%M')\n",
    "dparser2 = lambda date: pd.to_datetime(date, format='%d/%m/%Y %H:%M', errors='coerce')\n",
    "dparser3 = lambda date: pd.to_datetime(date, format='%d/%m/%Y %H:%M:%S', errors='coerce')\n",
    "dshortparser = lambda date: pd.datetime.strptime(date, '%d/%b/%Y')\n",
    "dshortparser2 = lambda date: pd.datetime.strptime(date, '%d/%m/%Y')\n",
    "dshortparser3 = lambda date: pd.to_datetime(date, format='%Y%m%d',errors='coerce')\n",
    "\n",
    "# Hide warnings \n",
    "import warnings \n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "    \n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# Another try\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Find local library directory - which should be located within a parent directory\n",
    "current_path = os.getcwd()\n",
    "os.chdir(\"..\")\n",
    "current_path = os.getcwd() \n",
    "libfiledir = \"library\"\n",
    "\n",
    "current_path\n",
    "direxists = False\n",
    "while direxists==False:\n",
    "    test_dir = os.path.join(current_path,libfiledir)\n",
    "    last_current_path = current_path\n",
    "    direxists = os.path.isdir(test_dir)\n",
    "    current_path = os.path.dirname(current_path)\n",
    "    if(current_path == last_current_path):\n",
    "        break;\n",
    "        \n",
    "if direxists == True:\n",
    "    sys.path.append(test_dir)\n",
    "    \n",
    "    \n",
    "from dataframe_common import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change to project directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/scottbarnes/Google Drive/1 Projects/Data Scientist Nanodegree'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/scottbarnes/Google Drive/1 Projects/Data Scientist Nanodegree/Udacity-Data-Scientist-Nanodegree/1-AirBnB-Analysis'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(os.path.join(os.getcwd() , \"Udacity-Data-Scientist-Nanodegree/1-AirBnB-Analysis\"))\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data ingestion / import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of source data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source data is held in the data directory. Data downloaded is for 12 months, from July 2019 to June 2020, and also includes a file containing neighbourhood geograhpic data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m10-July-2019\u001b[m\u001b[m       \u001b[34m14-September-2019\u001b[m\u001b[m  \u001b[34m5-November-2019\u001b[m\u001b[m    \u001b[34mNeighbourhood-data\u001b[m\u001b[m\r\n",
      "\u001b[34m10-May-2020\u001b[m\u001b[m        \u001b[34m15-March-2020\u001b[m\u001b[m      \u001b[34m9-August-2019\u001b[m\u001b[m\r\n",
      "\u001b[34m11-June-2020\u001b[m\u001b[m       \u001b[34m15-October-2019\u001b[m\u001b[m    \u001b[34m9-December-2019\u001b[m\u001b[m\r\n",
      "\u001b[34m14-April-2020\u001b[m\u001b[m      \u001b[34m16-February-2020\u001b[m\u001b[m   \u001b[34m9-January-2020\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data/AirBnB-Data-040920'\n",
    "!ls {data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each folder contains 5 files.  \n",
    "- listings.csv - add description\n",
    "- reviews.csv- add description\n",
    "- calendar.csv.gz - add description\n",
    "- reviews.csv.gz - add description\n",
    "- listings.csv.gz - add description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calendar_det.csv listings_det.csv reviews_det.csv\r\n",
      "listings.csv     reviews.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls {data_dir}/'9-January-2020'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to unzipping the required files is to create a list with the sub-directories containing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10-July-2019',\n",
       " '10-May-2020',\n",
       " '11-June-2020',\n",
       " '14-April-2020',\n",
       " '14-September-2019',\n",
       " '15-March-2020',\n",
       " '15-October-2019',\n",
       " '16-February-2020',\n",
       " '5-November-2019',\n",
       " '9-August-2019',\n",
       " '9-December-2019',\n",
       " '9-January-2020']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dir = !ls {data_dir}\n",
    "sub_dir.remove('Neighbourhood-data')\n",
    "sub_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function is created which will iterate through the subdirectories and the zipped files, and first rename them (so they are distinguishable from the non-zipped files) and then unzip in the same location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_data(periods):\n",
    "    ''' Takes in periods of data and renames and unzips .gz files'''    \n",
    "    file_names = ['calendar','listings','reviews']\n",
    "    for period in periods:\n",
    "        print(f'Unzipping files in subdirectory {period}')\n",
    "        for file_name in file_names:\n",
    "            print(f'   Unzipping {file_name}')\n",
    "            cur_file_path = os.path.join(data_dir,period,file_name + '.csv.gz')\n",
    "            new_file_path = os.path.join(data_dir,period,file_name + '_det.csv.gz')\n",
    "            ! mv {cur_file_path} {new_file_path}    \n",
    "            ! gunzip {new_file_path}\n",
    "            print(f'   Unzipped {file_name}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip_data(periods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion and processing of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be ingested and processed for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed calendar data (unzipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calendar data contains daily price and stay information for each listing. The price fields are formatted with special characters and so these will need to be cleaned up. The date field is currently at a daily level, and will be used to create date_month and date_year features.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43737744,2021-06-03,t,$83.00,$83.00,730,1125\r\n",
      "43737744,2021-06-04,t,$83.00,$83.00,730,1125\r\n",
      "43737744,2021-06-05,t,$83.00,$83.00,730,1125\r\n",
      "43737744,2021-06-06,t,$83.00,$83.00,730,1125\r\n",
      "43737744,2021-06-07,t,$83.00,$83.00,730,1125\r\n",
      "43737744,2021-06-08,t,$83.00,$83.00,730,1125\r\n",
      "43737744,2021-06-09,t,$83.00,$83.00,730,1125\r\n",
      "43737744,2021-06-10,t,$83.00,$83.00,730,1125\r\n",
      "43737744,2021-06-11,t,$83.00,$83.00,730,1125\r\n",
      "43737744,2021-06-12,t,$83.00,$83.00,730,1125\r\n"
     ]
    }
   ],
   "source": [
    "file_name = 'calendar_det.csv'\n",
    "! tail {os.path.join(data_dir,'11-June-2020','calendar_det.csv')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the last listing [here]([https://www.airbnb.co.uk/rooms/43737744?source_impression_id=p3_1599541680_kmdSBgOWT67FmBKm&check_in=2020-09-23&guests=1&adults=1&check_out=2020-10-22]) highlgihts that the night listing is in GBP not USD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function is created to clean the calendar file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_calendar(calendar):\n",
    "    calendar['date_month'] = calendar['date'].dt.month\n",
    "    calendar['date_year'] = calendar['date'].dt.year\n",
    "    calendar['price']  = calendar['price'].str.replace(\"$\",\"\")\n",
    "    calendar['price']  = calendar['price'].str.replace(\",\",\"\")\n",
    "    calendar['price'] = calendar['price'].astype(float)\n",
    "    calendar['available'] = np.where(calendar['available']==\"t\",1,0)\n",
    "    return calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function is created to iterate through the sub-directories containing the file, read in the file, clean is, and output it to feather file in a temporary directory for processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = 'tmp'\n",
    "processed_data = 'processed_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calendar_det10-July-2019.csv       calendar_det9-January-2020.csv\r\n",
      "calendar_det10-May-2020.csv        calendar_det9-January-2020.feather\r\n",
      "calendar_det9-January-2020         iris.feather\r\n"
     ]
    }
   ],
   "source": [
    "! ls {tmp_dir}/{processed_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_clean_calendars(periods):\n",
    "    for period in periods:\n",
    "        print(f'Processing calendar dataframe from {period}...')\n",
    "        try:\n",
    "            df  = pd.read_csv(os.path.join(data_dir,period,file_name))\n",
    "            print(\"   1. df read in\")\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            df  = clean_calendar(df)\n",
    "            print(\"   2. df cleaned\")\n",
    "            updated_file_name = file_name.replace(\".csv\",\"_\" + period + \".feather\")\n",
    "            df.to_feather(os.path.join(tmpdir,processed_data,updated_file_name))\n",
    "            print(\"   3. df renamed and outputted to feather\")\n",
    "            del df\n",
    "            print(\"   4. df deleted from memory\")\n",
    "            print(f'Processed calendar dataframe from {period}')\n",
    "        except MemoryError:\n",
    "            print('Memory error')\n",
    "        else:\n",
    "            print(f'Processed calendar dataframe from {period}')\n",
    "        finally:\n",
    "            print(f'Function complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function is executed to work through all sub directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "read_and_clean_calendars(periods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temporary directory now contains a sub-directory with the processed data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calendar_det10-July-2019.csv       calendar_det9-January-2020.csv\r\n",
      "calendar_det10-May-2020.csv        calendar_det9-January-2020.feather\r\n",
      "calendar_det9-January-2020         iris.feather\r\n"
     ]
    }
   ],
   "source": [
    "! ls {tmp_dir}/{processed_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processed file contains the added date feature columns and cleaned price columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",listing_id,date,available,price,adjusted_price,minimum_nights,maximum_nights,date_month,date_year,price_clean,available_flag\r\n",
      "0,78892,2019-07-12,f,$36.00,$36.00,3.0,31.0,7,2019,36.0,0\r\n",
      "1,78892,2019-07-13,f,$36.00,$36.00,3.0,31.0,7,2019,36.0,0\r\n",
      "2,78892,2019-07-14,f,$36.00,$36.00,3.0,31.0,7,2019,36.0,0\r\n",
      "3,78892,2019-07-15,f,$32.00,$32.00,3.0,31.0,7,2019,32.0,0\r\n",
      "4,78892,2019-07-16,f,$32.00,$32.00,3.0,31.0,7,2019,32.0,0\r\n",
      "5,78892,2019-07-17,f,$32.00,$32.00,3.0,31.0,7,2019,32.0,0\r\n",
      "6,78892,2019-07-18,f,$32.00,$32.00,3.0,31.0,7,2019,32.0,0\r\n",
      "7,78892,2019-07-19,f,$36.00,$36.00,3.0,31.0,7,2019,36.0,0\r\n",
      "8,78892,2019-07-20,f,$36.00,$36.00,3.0,31.0,7,2019,36.0,0\r\n"
     ]
    }
   ],
   "source": [
    "! head {tmp_dir}/{processed_data}/calendar_det10-July-2019.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
